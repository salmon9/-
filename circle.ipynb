import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data
from matplotlib import pyplot as plt

class Model (nn.Module):
  def __init__(self):
    super(Model, self).__init__()
    self.l1 = nn.Linear(1,20)
    self.l2 = nn.Linear(20,40)
    self.l3 = nn.Linear(40,1)

  def forward(self,x):
    x = F.relu(self.l1(x))
    x = F.relu(self.l2(x))
    x = self.l3(x)
    return x 

def get_dataset(n):
    x1 = -(np.random.random(n)) 
    x2 = np.random.random(n)
    x = x1 + x2
    y = np.sqrt(1-x*x) #ここを変える
    x = x.reshape(n, 1) #(n, 1)の配列にする
    y = y.reshape(n, 1) #(n, 1)の配列にする
    x = torch.FloatTensor(x) # floatに変える
    y = torch.FloatTensor(y) # floatに変える
    return torch.utils.data.TensorDataset(x, y)

data_number = 100000 #データ数
batch_size  = 1000 # 1つのミニバッチのデータ数
data_loader = torch.utils.data.DataLoader(get_dataset(data_number), batch_size=batch_size)

model = Model()
criterion = nn.MSELoss()
learning_rate = 1e-2
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

loss_log = [] 
epoch = 100
for t in range(epoch):
    for xt, yt in data_loader: 
        optimizer.zero_grad() 
        y_model = model(xt)
        loss = criterion(y_model, yt)
        loss.backward()
        optimizer.step()
    print(t, loss.item())
    loss_log.append(loss.item())

##学習したモデルと関数を比較する

fig = plt.figure()
ax = fig.add_subplot(111)
ax.set_aspect('equal')

x = np.linspace(-1, 1, 100)
plt.plot(x, np.sqrt(1-x*x), label="circle")
x_model = torch.FloatTensor(x.reshape(100,1))
y_model = model(x_model)
y = y_model.detach().np().reshape(1,100)[0] # プロット用に変換、detach()が必要

plt.plot(x, y, label='model')
plt.legend()
plt.xlabel('x')
plt.ylabel('y')
plt.show()

